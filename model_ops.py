# model_ops.py - ì´ë¯¸ì§€ í’ˆì§ˆ ê°œì„  ì™„ì „ ë²„ì „
"""
BioSecure Palm - ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ì²˜ë¦¬ ëª¨ë¸ ì—°ë™ ëª¨ë“ˆ

ê°œì„ ëœ ê¸°ëŠ¥:
- ğŸ¨ ìŠ¤ë§ˆíŠ¸ ë¦¬ì‚¬ì´ì¦ˆ (ë¹„ìœ¨ ìœ ì§€ + ê³ í’ˆì§ˆ ë³´ê°„)
- ğŸŒŸ ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ (ì„ ëª…í™”, ë…¸ì´ì¦ˆ ì œê±°)
- ğŸ“Š ì‹œê°ì  í’ˆì§ˆ í‰ê°€ (ì—£ì§€ ë°€ë„, í…ìŠ¤ì²˜ ë¶„ì„)
- ğŸ”§ ì™„í™”ëœ í’ˆì§ˆ ê¸°ì¤€ (ì›¹ìº  ìµœì í™”)
"""

import cv2
import torch
import numpy as np
import mediapipe as mp
import math
from PIL import Image
import torchvision.transforms as transforms
from ccnet import ccnet

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# MediaPipe ì´ˆê¸°í™”
def init_mediapipe_for_web():
    """ì›¹ ì‹¤ì‹œê°„ ì²˜ë¦¬ì— ìµœì í™”ëœ Mediapipe ì„¤ì •"""
    mp_hands = mp.solutions.hands
    hands = mp_hands.Hands(
        static_image_mode=False,
        max_num_hands=1,
        model_complexity=0,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.3
    )
    return mp_hands, hands

mp_hands, hands = init_mediapipe_for_web()
mp_drawing = mp.solutions.drawing_utils

# ROI í†µê³„ ì¶”ì ìš©
class ROIStats:
    def __init__(self):
        self.total_frames = 0
        self.roi_detected_frames = 0
        self.avg_quality = 0
        self.quality_history = []
        
    def update(self, roi_detected, quality=None):
        self.total_frames += 1
        if roi_detected:
            self.roi_detected_frames += 1
            if quality is not None:
                self.quality_history.append(quality)
                if len(self.quality_history) > 100:
                    self.quality_history.pop(0)
                self.avg_quality = sum(self.quality_history) / len(self.quality_history)
    
    def get_detection_rate(self):
        if self.total_frames == 0:
            return 0
        return (self.roi_detected_frames / self.total_frames) * 100
    
    def reset(self):
        self.total_frames = 0
        self.roi_detected_frames = 0
        self.avg_quality = 0
        self.quality_history = []

web_roi_stats = ROIStats()

#########################
# ğŸ¨ ì´ë¯¸ì§€ í’ˆì§ˆ ê°œì„  í•¨ìˆ˜ë“¤
#########################

def smart_resize_with_padding(image, target_size=128):
    """
    ğŸ¨ ìŠ¤ë§ˆíŠ¸ ë¦¬ì‚¬ì´ì¦ˆ: ë¹„ìœ¨ ìœ ì§€ + íŒ¨ë”©ìœ¼ë¡œ ì´ìœ ì •ì‚¬ê°í˜• ë§Œë“¤ê¸°
    """
    if image is None:
        return None
    
    h, w = image.shape[:2]
    
    # 1. ë¹„ìœ¨ ê³„ì‚°
    aspect_ratio = w / h
    
    if aspect_ratio > 1:  # ê°€ë¡œê°€ ë” ê¸¸ ê²½ìš°
        new_w = target_size
        new_h = int(target_size / aspect_ratio)
    else:  # ì„¸ë¡œê°€ ë” ê¸¸ê±°ë‚˜ ì •ì‚¬ê°í˜•ì¸ ê²½ìš°
        new_h = target_size
        new_w = int(target_size * aspect_ratio)
    
    # 2. ê³ í’ˆì§ˆ ë¦¬ì‚¬ì´ì¦ˆ (LANCZOS ì‚¬ìš©)
    resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
    
    # 3. íŒ¨ë”©ìœ¼ë¡œ ì •ì‚¬ê°í˜• ë§Œë“¤ê¸°
    pad_h = target_size - new_h
    pad_w = target_size - new_w
    
    top = pad_h // 2
    bottom = pad_h - top
    left = pad_w // 2
    right = pad_w - left
    
    # 4. ë°˜ì‚¬ íŒ¨ë”© (ê²€ì€ìƒ‰ ëŒ€ì‹  ì´ë¯¸ì§€ ê²½ê³„ ë°˜ì‚¬)
    padded = cv2.copyMakeBorder(
        resized, top, bottom, left, right, 
        cv2.BORDER_REFLECT_101
    )
    
    return padded

def enhance_image_quality(image):
    """
    ğŸŒŸ ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ ì²˜ë¦¬
    """
    if image is None:
        return None
    
    # 1. ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ì œê±°
    denoised = cv2.GaussianBlur(image, (3, 3), 0.5)
    
    # 2. ì–¸ìƒ¤í”„ ë§ˆìŠ¤í‚¹ìœ¼ë¡œ ì„ ëª…ë„ í–¥ìƒ
    gaussian = cv2.GaussianBlur(denoised, (0, 0), 2.0)
    unsharp = cv2.addWeighted(denoised, 1.5, gaussian, -0.5, 0)
    
    # 3. CLAHEë¡œ ëŒ€ë¹„ í–¥ìƒ
    if len(image.shape) == 3:
        gray = cv2.cvtColor(unsharp, cv2.COLOR_BGR2GRAY)
    else:
        gray = unsharp
    
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(gray)
    
    # 4. íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”ë¡œ ë°ê¸° ì¡°ì •
    equalized = cv2.equalizeHist(enhanced)
    
    # 5. ì›ë³¸ê³¼ ë¸”ë Œë”© (ë„ˆë¬´ ê³¼í•˜ì§€ ì•Šê²Œ)
    final = cv2.addWeighted(enhanced, 0.7, equalized, 0.3, 0)
    
    return final

def create_beautiful_roi(roi_image, target_size=128):
    """
    ğŸ¨ ì•„ë¦„ë‹¤ìš´ ROI ì´ë¯¸ì§€ ìƒì„± (ì „ì²´ íŒŒì´í”„ë¼ì¸)
    """
    if roi_image is None:
        return None
    
    try:
        # 1. ì›ë³¸ì´ ì»¬ëŸ¬ë©´ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
        if len(roi_image.shape) == 3:
            gray = cv2.cvtColor(roi_image, cv2.COLOR_BGR2GRAY)
        else:
            gray = roi_image.copy()
        
        # 2. í’ˆì§ˆ í–¥ìƒ
        enhanced = enhance_image_quality(gray)
        
        # 3. ìŠ¤ë§ˆíŠ¸ ë¦¬ì‚¬ì´ì¦ˆ (ë¹„ìœ¨ ìœ ì§€)
        resized = smart_resize_with_padding(enhanced, target_size)
        
        # 4. ìµœì¢… í›„ì²˜ë¦¬
        # ì•½ê°„ì˜ ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë¶€ë“œëŸ½ê²Œ
        final = cv2.GaussianBlur(resized, (3, 3), 0.8)
        
        # 5. ì»¬ëŸ¬ë¡œ ë³€í™˜ (ì›¹ì—ì„œ í‘œì‹œìš©)
        if len(final.shape) == 2:
            final_color = cv2.cvtColor(final, cv2.COLOR_GRAY2BGR)
        else:
            final_color = final
        
        return final_color
        
    except Exception as e:
        print(f"ğŸ¨ ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ ì¤‘ ì˜¤ë¥˜: {e}")
        # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë¦¬ì‚¬ì´ì¦ˆë¼ë„ ë°˜í™˜
        return cv2.resize(roi_image, (target_size, target_size), interpolation=cv2.INTER_LANCZOS4)

#########################
# í’ˆì§ˆ í‰ê°€ í•¨ìˆ˜ë“¤
#########################

def assess_roi_quality_enhanced(roi, threshold=0.35):
    """
    ğŸ”¥ ì™„í™”ëœ ROI í’ˆì§ˆ í‰ê°€ - ì›¹ìº  í™˜ê²½ì— ë§ê²Œ í˜„ì‹¤ì  ê¸°ì¤€ ì ìš©
    """
    if roi is None or roi.size == 0:
        return False, 0.0, "ROI ì—†ìŒ"
    
    try:
        # ROI í¬ê¸° í™•ì¸
        height, width = roi.shape[:2]
        if height < 50 or width < 50:
            return False, 0.0, "ROI í¬ê¸° ë„ˆë¬´ ì‘ìŒ"
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if len(roi.shape) == 3:
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        else:
            gray = roi.copy()
        
        # 1. ì„ ëª…ë„ í‰ê°€ (ì™„í™”ëœ ê¸°ì¤€)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        sharpness_score = min(laplacian_var / 50, 1.0)  # 100 â†’ 50ìœ¼ë¡œ ì™„í™”
        
        # 2. ëŒ€ë¹„ë„ í‰ê°€ (ì™„í™”ëœ ê¸°ì¤€)
        contrast = gray.std()
        contrast_score = min(contrast / 25, 1.0)  # 50 â†’ 25ë¡œ ì™„í™”
        
        # 3. ì½˜í…ì¸  ë¹„ìœ¨ (ì™„í™”ëœ ê¸°ì¤€)
        content_pixels = np.count_nonzero(gray)
        total_pixels = gray.shape[0] * gray.shape[1]
        content_ratio = content_pixels / total_pixels
        content_score = min(content_ratio * 1.2, 1.0)  # ë³´ì • ê³„ìˆ˜ ì¶”ê°€
        
        # 4. ë°ê¸° ë¶„í¬ í‰ê°€ (ìƒˆë¡œ ì¶”ê°€ - ì™„í™”ëœ ê¸°ì¤€)
        mean_brightness = gray.mean()
        brightness_score = 1.0
        if mean_brightness < 50:  # ë„ˆë¬´ ì–´ë‘ì›€
            brightness_score = mean_brightness / 50
        elif mean_brightness > 200:  # ë„ˆë¬´ ë°ìŒ
            brightness_score = (255 - mean_brightness) / 55
        
        # 5. ì¢…í•© ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ì¹˜ ì¡°ì •)
        overall_score = (
            sharpness_score * 0.25 +      # ì„ ëª…ë„ ë¹„ì¤‘ ì¤„ì„
            contrast_score * 0.25 +       # ëŒ€ë¹„ë„ ë¹„ì¤‘ ì¤„ì„
            content_score * 0.35 +        # ì½˜í…ì¸  ë¹„ì¤‘ ë†’ì„
            brightness_score * 0.15       # ë°ê¸° ì¶”ê°€
        )
        
        # 6. í’ˆì§ˆ íŒì •
        is_good = overall_score >= threshold
        
        # 7. ìƒì„¸ ì´ìœ  ì œê³µ
        if not is_good:
            reasons = []
            if sharpness_score < 0.3:
                reasons.append("ì„ ëª…ë„ ë¶€ì¡±")
            if contrast_score < 0.3:
                reasons.append("ëŒ€ë¹„ë„ ë¶€ì¡±")
            if content_score < 0.5:
                reasons.append("ì†ë°”ë‹¥ ì˜ì—­ ë¶€ì¡±")
            if brightness_score < 0.5:
                reasons.append("ì¡°ëª… ë¬¸ì œ")
            
            reason = ", ".join(reasons) if reasons else "ì¢…í•© ì ìˆ˜ ë¶€ì¡±"
        else:
            if overall_score >= 0.7:
                reason = "ìš°ìˆ˜ í’ˆì§ˆ"
            elif overall_score >= 0.5:
                reason = "ì–‘í˜¸ í’ˆì§ˆ"
            else:
                reason = "ìµœì†Œ í’ˆì§ˆ í†µê³¼"
        
        return is_good, overall_score, reason
        
    except Exception as e:
        print(f"í’ˆì§ˆ í‰ê°€ ì˜¤ë¥˜: {e}")
        return False, 0.0, f"í‰ê°€ ì˜¤ë¥˜: {str(e)}"

def assess_roi_quality_visual(roi, threshold=0.35):
    """
    ğŸ¨ ì‹œê°ì  í’ˆì§ˆê¹Œì§€ ê³ ë ¤í•œ ROI í‰ê°€
    """
    if roi is None or roi.size == 0:
        return False, 0.0, "ROI ì—†ìŒ"
    
    try:
        # ê¸°ë³¸ í’ˆì§ˆ í‰ê°€
        is_good, basic_score, reason = assess_roi_quality_enhanced(roi, threshold)
        
        # ì¶”ê°€: ì‹œê°ì  í’ˆì§ˆ í‰ê°€
        if len(roi.shape) == 3:
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        else:
            gray = roi.copy()
        
        # 1. ì—£ì§€ ë°€ë„ (ì†ë°”ë‹¥ ë¼ì¸ì´ ì˜ ë³´ì´ëŠ”ì§€)
        edges = cv2.Canny(gray, 50, 150)
        edge_density = np.count_nonzero(edges) / (gray.shape[0] * gray.shape[1])
        edge_score = min(edge_density * 10, 1.0)  # ì •ê·œí™”
        
        # 2. í…ìŠ¤ì²˜ ë‹¤ì–‘ì„± (ì†ë°”ë‹¥ íŒ¨í„´ì˜ ë³µì¡ë„)
        lbp = cv2.calcHist([gray], [0], None, [256], [0, 256])
        texture_score = min(np.std(lbp) / 1000, 1.0)  # ì •ê·œí™”
        
        # 3. ì¢…í•© ì‹œê°ì  ì ìˆ˜
        visual_score = (edge_score * 0.6 + texture_score * 0.4)
        
        # 4. ìµœì¢… ì ìˆ˜ (ê¸°ë³¸ + ì‹œê°ì )
        final_score = (basic_score * 0.7 + visual_score * 0.3)
        
        is_beautiful = final_score >= threshold
        
        if is_beautiful:
            if final_score >= 0.8:
                visual_reason = "ìµœê³  í’ˆì§ˆ (ë§¤ìš° ì„ ëª…)"
            elif final_score >= 0.6:
                visual_reason = "ìš°ìˆ˜ í’ˆì§ˆ (ì„ ëª…í•¨)"
            else:
                visual_reason = "ì–‘í˜¸ í’ˆì§ˆ (ì ë‹¹í•¨)"
        else:
            visual_reason = f"í’ˆì§ˆ ê°œì„  í•„ìš” ({reason})"
        
        return is_beautiful, final_score, visual_reason
        
    except Exception as e:
        return False, 0.0, f"í‰ê°€ ì˜¤ë¥˜: {str(e)}"

def assess_roi_quality_super_relaxed(roi, threshold=0.15):
    """
    ğŸ”¥ ë§¤ìš° ì™„í™”ëœ ROI í’ˆì§ˆ í‰ê°€ - ê±°ì˜ ëª¨ë“  ê²½ìš°ì— í†µê³¼í•˜ë„ë¡ ì„¤ì •
    """
    if roi is None or roi.size == 0:
        return False, 0.0, "ROI ì—†ìŒ"
    
    try:
        # ROI í¬ê¸° í™•ì¸ (ë” ê´€ëŒ€í•˜ê²Œ)
        height, width = roi.shape[:2]
        if height < 30 or width < 30:  # 50 â†’ 30ìœ¼ë¡œ ì™„í™”
            return False, 0.0, "ROI í¬ê¸° ë„ˆë¬´ ì‘ìŒ"
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if len(roi.shape) == 3:
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        else:
            gray = roi.copy()
        
        # 1. ì„ ëª…ë„ í‰ê°€ (ë§¤ìš° ì™„í™”ëœ ê¸°ì¤€)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        sharpness_score = min(laplacian_var / 20, 1.0)  # 50 â†’ 20ìœ¼ë¡œ ëŒ€í­ ì™„í™”
        
        # 2. ëŒ€ë¹„ë„ í‰ê°€ (ë§¤ìš° ì™„í™”ëœ ê¸°ì¤€)
        contrast = gray.std()
        contrast_score = min(contrast / 15, 1.0)  # 25 â†’ 15ë¡œ ëŒ€í­ ì™„í™”
        
        # 3. ì½˜í…ì¸  ë¹„ìœ¨ (ë§¤ìš° ì™„í™”ëœ ê¸°ì¤€)
        content_pixels = np.count_nonzero(gray)
        total_pixels = gray.shape[0] * gray.shape[1]
        content_ratio = content_pixels / total_pixels
        content_score = min(content_ratio * 2.0, 1.0)  # 1.2 â†’ 2.0ìœ¼ë¡œ ëŒ€í­ ì™„í™”
        
        # 4. ë°ê¸° ë¶„í¬ í‰ê°€ (ë§¤ìš° ê´€ëŒ€í•œ ê¸°ì¤€)
        mean_brightness = gray.mean()
        brightness_score = 1.0
        if mean_brightness < 20:  # 50 â†’ 20ìœ¼ë¡œ ì™„í™” (ë§¤ìš° ì–´ë‘ì›Œë„ OK)
            brightness_score = mean_brightness / 20
        elif mean_brightness > 235:  # 200 â†’ 235ë¡œ ì™„í™” (ë§¤ìš° ë°ì•„ë„ OK)
            brightness_score = (255 - mean_brightness) / 20
        
        # 5. ì¢…í•© ì ìˆ˜ ê³„ì‚° (ë” ê´€ëŒ€í•œ ê°€ì¤‘ì¹˜)
        overall_score = (
            sharpness_score * 0.15 +      # ì„ ëª…ë„ ë¹„ì¤‘ ë” ì¤„ì„
            contrast_score * 0.15 +       # ëŒ€ë¹„ë„ ë¹„ì¤‘ ë” ì¤„ì„
            content_score * 0.50 +        # ì½˜í…ì¸  ë¹„ì¤‘ ë” ë†’ì„
            brightness_score * 0.20       # ë°ê¸° ë¹„ì¤‘ ë†’ì„
        )
        
        # ì¶”ê°€ ë³´ë„ˆìŠ¤: ê¸°ë³¸ ì ìˆ˜ê°€ ë„ˆë¬´ ë‚®ì•„ë„ ìµœì†Œ ë³´ì¥
        if content_ratio > 0.3:  # ê¸°ë³¸ì ìœ¼ë¡œ ì†ì´ ë³´ì´ê¸°ë§Œ í•˜ë©´
            overall_score = max(overall_score, 0.2)  # ìµœì†Œ 0.2ì  ë³´ì¥
        
        # 6. í’ˆì§ˆ íŒì • (ë§¤ìš° ê´€ëŒ€í•œ ì„ê³„ê°’)
        is_good = overall_score >= threshold
        
        # 7. ìƒì„¸ ì´ìœ  ì œê³µ
        if not is_good:
            reasons = []
            if sharpness_score < 0.1:  # 0.3 â†’ 0.1ë¡œ ì™„í™”
                reasons.append("ë§¤ìš° íë¦¼")
            if contrast_score < 0.1:   # 0.3 â†’ 0.1ë¡œ ì™„í™”
                reasons.append("ë§¤ìš° ë‚®ì€ ëŒ€ë¹„")
            if content_score < 0.2:    # 0.5 â†’ 0.2ë¡œ ì™„í™”
                reasons.append("ì†ë°”ë‹¥ ê±°ì˜ ì•ˆ ë³´ì„")
            if brightness_score < 0.2: # 0.5 â†’ 0.2ë¡œ ì™„í™”
                reasons.append("ê·¹ë‹¨ì  ì¡°ëª…")
            
            reason = ", ".join(reasons) if reasons else "ê¸°ë³¸ ê¸°ì¤€ ë¯¸ë‹¬"
        else:
            if overall_score >= 0.5:
                reason = "ìš°ìˆ˜ í’ˆì§ˆ"
            elif overall_score >= 0.3:
                reason = "ì–‘í˜¸ í’ˆì§ˆ"
            elif overall_score >= 0.15:
                reason = "ìµœì†Œ í’ˆì§ˆ í†µê³¼"
            else:
                reason = "ê¸°ë³¸ í’ˆì§ˆ í†µê³¼"
        
        print(f"[í’ˆì§ˆ í‰ê°€] ì ìˆ˜: {overall_score:.3f}, í†µê³¼: {is_good}, ì´ìœ : {reason}")
        return is_good, overall_score, reason
        
    except Exception as e:
        print(f"í’ˆì§ˆ í‰ê°€ ì˜¤ë¥˜: {e}")
        return False, 0.0, f"í‰ê°€ ì˜¤ë¥˜: {str(e)}"

#########################
# CCNet ëª¨ë¸ ë¡œë“œ
#########################

def load_ccnet_model(model_path="/Users/kimeunsu/Desktop/ê³µë¶€/ì¡¸ì‘ ë…¼ë¬¸/CCNet-main-2/access_system1/models/checkpoint_step_951.pth",
                     num_classes=1000,
                     weight=0.8):
    """
    ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ì²˜ë¦¬ CCNet ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
    """
    print(f"ğŸš€ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ì²˜ë¦¬ CCNet ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
    model = ccnet(num_classes=num_classes, weight=weight)

    try:
        print(f"ğŸ“ ëª¨ë¸ ë¡œë“œ ì‹œë„: {model_path}")
        state_dict = torch.load(model_path, map_location=torch.device('cpu'))
        model.load_state_dict(state_dict, strict=False)
        print(f"âœ… ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ì²˜ë¦¬ CCNet ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        
        # ëª¨ë¸ ìƒì„¸ ì •ë³´ ì¶œë ¥
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"ğŸ“Š ëª¨ë¸ ìƒì„¸ ì •ë³´:")
        print(f"   - ì´ íŒŒë¼ë¯¸í„°: {total_params:,}ê°œ")
        print(f"   - í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {trainable_params:,}ê°œ")
        print(f"   - ì•„í‚¤í…ì²˜: ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ì²˜ë¦¬ CCNet")
        print(f"   - í’ˆì§ˆ ê¸°ì¤€: 0.35 (ì›¹ìº  ìµœì í™”)")
        print(f"   - ğŸ¨ ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ: í™œì„±í™”")
        
    except FileNotFoundError as e:
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        raise RuntimeError("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise e
    
    model.eval()
    model.to(torch.device('cpu'))
    print("ğŸš€ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ì²˜ë¦¬ CCNetì´ evaluation ëª¨ë“œë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return model

#########################
# ROI ì¶”ì¶œ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤
#########################

def normalize_for_ccnet(image):
    """CCNet NormSingleROIì™€ ë™ì¼í•œ ì •ê·œí™”"""
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image.copy()
    
    normalized = gray.astype(np.float32)
    
    mask = normalized > 0
    if mask.sum() > 0:
        mean_val = normalized[mask].mean()
        std_val = normalized[mask].std()
        normalized[mask] = (normalized[mask] - mean_val) / (std_val + 1e-6)
    
    return normalized

def assess_roi_quality(roi, threshold=0.25):
    """ê¸°ë³¸ ROI í’ˆì§ˆ í‰ê°€ (ë” ê´€ëŒ€í•œ ê¸°ì¤€)"""
    if roi is None or roi.size == 0:
        return False, 0.0
    
    # ì„ ëª…ë„ (Laplacian variance)
    laplacian_var = cv2.Laplacian(roi, cv2.CV_64F).var()
    sharpness_score = min(laplacian_var / 30, 1.0)  # ë” ê´€ëŒ€í•˜ê²Œ
    
    # ëŒ€ë¹„ë„
    contrast = roi.std()
    contrast_score = min(contrast / 20, 1.0)  # ë” ê´€ëŒ€í•˜ê²Œ
    
    # ì½˜í…ì¸  ë¹„ìœ¨
    if len(roi.shape) == 3:
        content_pixels = np.count_nonzero(cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY))
    else:
        content_pixels = np.count_nonzero(roi)
    content_ratio = content_pixels / (128 * 128)
    
    # ì¢…í•© ì ìˆ˜ (ë” ê´€ëŒ€í•œ ê°€ì¤‘ì¹˜)
    overall_score = (sharpness_score * 0.3 + contrast_score * 0.3 + content_ratio * 0.4)
    
    is_good = overall_score > threshold
    return is_good, overall_score

def classify_hand(mp_hands, hand_landmarks, image_width):
    """ì† ë°©í–¥ ë¶„ë¥˜ (ì¢Œ/ìš°)"""
    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]
    index_base = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP]
    thumb_tip_x_px = thumb_tip.x * image_width
    index_base_x_px = index_base.x * image_width
    return 'Right' if thumb_tip_x_px > index_base_x_px else 'Left'

def align_hand_rotation(image, mp_hands, hand_landmarks):
    """ì† íšŒì „ ë³´ì •"""
    image_width, image_height = image.shape[1], image.shape[0]
    hand_orientation = classify_hand(mp_hands, hand_landmarks, image_width)

    index_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP]
    pinky_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_MCP]

    x1, y1 = index_mcp.x, index_mcp.y
    x2, y2 = pinky_mcp.x, pinky_mcp.y
    distance = math.hypot(x2 - x1, y2 - y1)
    
    if distance == 0:
        return image, 0
    
    unit_vector = ((x2 - x1) / distance, (y2 - y1) / distance)
    angle_with_horizontal = math.degrees(math.atan2(unit_vector[1], unit_vector[0]))

    if hand_orientation == "Right":
        if -180 <= angle_with_horizontal <= -90:
            rotation_angle = angle_with_horizontal + 180
        elif 0 <= angle_with_horizontal <= 180:
            rotation_angle = angle_with_horizontal - 180
        else:
            rotation_angle = 180 - angle_with_horizontal
    else:
        if -180 <= angle_with_horizontal <= -90:
            rotation_angle = angle_with_horizontal + 180
        else:
            rotation_angle = angle_with_horizontal

    center = (image_width // 2, image_height // 2)
    rotation_matrix = cv2.getRotationMatrix2D(center, rotation_angle, 1.0)
    rotated_image = cv2.warpAffine(image, rotation_matrix, (image_width, image_height),
                                   flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)

    return rotated_image, rotation_angle

def enhance_for_ccnet(image):
    """CCNetì— ìµœì í™”ëœ ì´ë¯¸ì§€ í’ˆì§ˆ ê°œì„ """
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image
    
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    enhanced = clahe.apply(gray)
    
    gaussian = cv2.GaussianBlur(enhanced, (0, 0), 1.0)
    unsharp = cv2.addWeighted(enhanced, 1.2, gaussian, -0.2, 0)
    
    return unsharp

def ccnet_optimized_square_transform(image, target_size=128):
    """ğŸ¨ ê°œì„ ëœ CCNet ì •ì‚¬ê°í˜• ë³€í™˜"""
    # ìƒˆë¡œìš´ í’ˆì§ˆ í–¥ìƒ í•¨ìˆ˜ ì‚¬ìš©
    return create_beautiful_roi(image, target_size)

#########################
# ì‹œê°í™” í•¨ìˆ˜ë“¤
#########################

def get_hand_roi_with_visualization(img_bgr):
    """ì‹œê°í™” ì •ë³´ê°€ í¬í•¨ëœ ROI ì¶”ì¶œ"""
    try:
        vis_image = img_bgr.copy()
        
        image_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
        results = hands.process(image_rgb)

        if not results.multi_hand_landmarks:
            cv2.putText(vis_image, "No Hand Detected", (50, 50), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            return vis_image

        hand_landmarks = results.multi_hand_landmarks[0]
        
        mp_drawing.draw_landmarks(
            vis_image, hand_landmarks, mp_hands.HAND_CONNECTIONS,
            mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2),
            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2)
        )
        
        h, w, _ = img_bgr.shape
        x_list = [lm.x for lm in hand_landmarks.landmark]
        y_list = [lm.y for lm in hand_landmarks.landmark]

        xmin, xmax = int(min(x_list) * w), int(max(x_list) * w)
        ymin, ymax = int(min(y_list) * h), int(max(y_list) * h)

        xmin = max(0, xmin)
        ymin = max(0, ymin)
        xmax = min(w, xmax)
        ymax = min(h, ymax)

        if (xmax - xmin) <= 0 or (ymax - ymin) <= 0:
            cv2.putText(vis_image, "Invalid ROI", (50, 50), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            return vis_image
        
        cv2.rectangle(vis_image, (xmin, ymin), (xmax, ymax), (0, 255, 255), 3)
        
        if len(hand_landmarks.landmark) >= 9:
            middle_tip = hand_landmarks.landmark[8]
            wrist = hand_landmarks.landmark[0]
            
            middle_tip_px = (int(middle_tip.x * w), int(middle_tip.y * h))
            wrist_px = (int(wrist.x * w), int(wrist.y * h))
            
            cv2.arrowedLine(vis_image, wrist_px, middle_tip_px, (255, 0, 255), 3)
        
        cv2.putText(vis_image, "High Quality CCNet", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        return vis_image
        
    except Exception as e:
        cv2.putText(img_bgr, f"Error: {str(e)[:30]}", (10, 50), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
        return img_bgr

def extract_palm_roi_like_roi1(img_bgr):
    """ğŸ¨ roi1.py ë°©ì‹ê³¼ ë™ì¼í•œ ì†ë°”ë‹¥ ROI ì¶”ì¶œ - ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ì²˜ë¦¬ ë²„ì „"""
    try:
        image_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
        results = hands.process(image_rgb)

        if not results.multi_hand_landmarks:
            return None, "No Hand Detected"

        hand_landmarks = results.multi_hand_landmarks[0]
        image_width, image_height = img_bgr.shape[1], img_bgr.shape[0]
        
        index_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP]
        middle_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP]
        ring_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_MCP]
        pinky_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_MCP]
        wrist = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]
        thumb_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_CMC]

        points_dict = {
            'index_mcp': (int(index_mcp.x * image_width), int(index_mcp.y * image_height)),
            'middle_mcp': (int(middle_mcp.x * image_width), int(middle_mcp.y * image_height)),
            'ring_mcp': (int(ring_mcp.x * image_width), int(ring_mcp.y * image_height)),
            'pinky_mcp': (int(pinky_mcp.x * image_width), int(pinky_mcp.y * image_height)),
            'wrist': (int(wrist.x * image_width), int(wrist.y * image_height)),
            'thumb_mcp': (int(thumb_mcp.x * image_width), int(thumb_mcp.y * image_height))
        }

        wrist_pinky_horiz = (points_dict['wrist'][0], points_dict['pinky_mcp'][1])

        points = np.array([
            points_dict['index_mcp'],
            points_dict['middle_mcp'],
            points_dict['ring_mcp'],
            points_dict['pinky_mcp'],
            wrist_pinky_horiz,
            points_dict['wrist'],
            points_dict['thumb_mcp']
        ], dtype=np.int32)

        rotated_image, rotation_angle = align_hand_rotation(img_bgr, mp_hands, hand_landmarks)
        
        center = (image_width // 2, image_height // 2)
        rotation_matrix = cv2.getRotationMatrix2D(center, rotation_angle, 1.0)
        
        ones = np.ones((points.shape[0], 1))
        points_homogeneous = np.hstack([points, ones]).astype(np.float32)
        
        new_points = cv2.transform(np.array([points_homogeneous]), rotation_matrix).squeeze().astype(np.int32)

        x, y, w, h = cv2.boundingRect(new_points)
        
        if w == 0 or h == 0:
            return None, "Invalid bounding box"

        roi = rotated_image[y:y+h, x:x+w]
        
        # ğŸ”¥ ì™„í™”ëœ í’ˆì§ˆ í‰ê°€
        is_good, quality_score = assess_roi_quality(roi, threshold=0.25)  # ë” ê´€ëŒ€í•˜ê²Œ
        if not is_good:
            return None, f"Low quality (score: {quality_score:.3f})"
        
        # ğŸŒŸ ìƒˆë¡œìš´ í’ˆì§ˆ í–¥ìƒ íŒŒì´í”„ë¼ì¸ ì ìš©
        beautiful_roi = create_beautiful_roi(roi, target_size=128)
        
        return beautiful_roi, f"Success (quality: {quality_score:.3f})"
        
    except Exception as e:
        print(f"ROI ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return None, f"Error: {str(e)}"

def get_hand_roi_for_registration(img_bgr):
    """ë“±ë¡ìš© ROI ì¶”ì¶œ - ì™„í™”ëœ ê¸°ì¤€ ì ìš©"""
    try:
        image_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
        results = hands.process(image_rgb)

        if not results.multi_hand_landmarks:
            return None

        hand_landmarks = results.multi_hand_landmarks[0]
        image_width, image_height = img_bgr.shape[1], img_bgr.shape[0]
        
        # ì†ë°”ë‹¥ ì£¼ìš” ì ë“¤ ì¶”ì¶œ
        index_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP]
        middle_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP]
        ring_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_MCP]
        pinky_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_MCP]
        wrist = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]
        thumb_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_CMC]

        points_dict = {
            'index_mcp': (int(index_mcp.x * image_width), int(index_mcp.y * image_height)),
            'middle_mcp': (int(middle_mcp.x * image_width), int(middle_mcp.y * image_height)),
            'ring_mcp': (int(ring_mcp.x * image_width), int(ring_mcp.y * image_height)),
            'pinky_mcp': (int(pinky_mcp.x * image_width), int(pinky_mcp.y * image_height)),
            'wrist': (int(wrist.x * image_width), int(wrist.y * image_height)),
            'thumb_mcp': (int(thumb_mcp.x * image_width), int(thumb_mcp.y * image_height))
        }

        # ì†ë°”ë‹¥ ì˜ì—­ ì •ì˜
        wrist_pinky_horiz = (points_dict['wrist'][0], points_dict['pinky_mcp'][1])
        points = np.array([
            points_dict['index_mcp'],
            points_dict['middle_mcp'],
            points_dict['ring_mcp'],
            points_dict['pinky_mcp'],
            wrist_pinky_horiz,
            points_dict['wrist'],
            points_dict['thumb_mcp']
        ], dtype=np.int32)

        # íšŒì „ ë³´ì •
        rotated_image, rotation_angle = align_hand_rotation(img_bgr, mp_hands, hand_landmarks)
        
        # íšŒì „ í›„ ì¢Œí‘œ ë³€í™˜
        center = (image_width // 2, image_height // 2)
        rotation_matrix = cv2.getRotationMatrix2D(center, rotation_angle, 1.0)
        ones = np.ones((points.shape[0], 1))
        points_homogeneous = np.hstack([points, ones]).astype(np.float32)
        new_points = cv2.transform(np.array([points_homogeneous]), rotation_matrix).squeeze().astype(np.int32)

        # ë°”ìš´ë”© ë°•ìŠ¤
        x, y, w, h = cv2.boundingRect(new_points)
        
        if w == 0 or h == 0:
            return None

        # ROI ì¶”ì¶œ
        roi = rotated_image[y:y+h, x:x+w]
        
        # ğŸŒŸ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ì²˜ë¦¬ ì ìš©
        beautiful_roi = create_beautiful_roi(roi, target_size=128)
        
        return beautiful_roi
        
    except Exception as e:
        print(f"ë“±ë¡ìš© ROI ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def get_hand_roi(img_bgr):
    """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜"""
    roi, message = extract_palm_roi_like_roi1(img_bgr)
    return roi

#########################
# ì „ì²˜ë¦¬ ì„¤ì •
#########################
transform_ops = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((128, 128)),
    transforms.ToTensor()
])

#########################
# ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ì²˜ë¦¬ CCNet ì„ë² ë”© ì¶”ì¶œ í•¨ìˆ˜
#########################
def extract_embedding(img_bgr, model):
    """
    ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ì²˜ë¦¬ CCNet ì„ë² ë”© ì¶”ì¶œ
    1) ê³ í’ˆì§ˆ ì†ë°”ë‹¥ ROI ì¶”ì¶œ
    2) CCNet ì •ê·œí™” ì ìš©
    3) CCNet -> ì„ë² ë”©
    """
    roi = get_hand_roi(img_bgr)
    if roi is None:
        print("âŒ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ì²˜ë¦¬ CCNetìš© ì†ë°”ë‹¥ ROI ì¶”ì¶œ ì‹¤íŒ¨!")
        return None

    if len(roi.shape) == 3:
        roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    else:
        roi_gray = roi

    normalized_roi = normalize_for_ccnet(roi_gray)
    display_roi = ((normalized_roi + 3) * 40).clip(0, 255).astype(np.uint8)
    roi_for_transform = display_roi
    
    roi_tensor = transform_ops(roi_for_transform).unsqueeze(0).to(device)

    with torch.no_grad():
        emb = model.getFeatureCode(roi_tensor)
    
    emb_np = emb.squeeze().cpu().numpy()
    
    print("âœ… ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ì²˜ë¦¬ CCNetìœ¼ë¡œ ì„ë² ë”© ì¶”ì¶œ ì„±ê³µ!")
    
    return emb_np

#########################
# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
#########################
if __name__ == "__main__":
    print("ğŸš€ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ì²˜ë¦¬ CCNet í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    print("="*60)
    print("ğŸ¨ ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ ê¸°ëŠ¥:")
    print("   - ìŠ¤ë§ˆíŠ¸ ë¦¬ì‚¬ì´ì¦ˆ (ë¹„ìœ¨ ìœ ì§€)")
    print("   - LANCZOS4 ë³´ê°„ë²•")
    print("   - ì–¸ìƒ¤í”„ ë§ˆìŠ¤í‚¹")
    print("   - CLAHE ëŒ€ë¹„ í–¥ìƒ")
    print("   - ë°˜ì‚¬ íŒ¨ë”©")
    print("ğŸ¯ í’ˆì§ˆ ì„ê³„ê°’: 0.35 (ì™„í™”ëœ ê¸°ì¤€)")
    print("ğŸ“ˆ ì˜ˆìƒ í†µê³¼ìœ¨: 80-90%")
    print("ğŸ›¡ï¸ ì—¬ì „íˆ ìµœì†Œí•œì˜ í’ˆì§ˆì€ ë³´ì¥")
    print("ğŸ”§ ì›¹ìº  í™˜ê²½ì— ìµœì í™”ëœ í˜„ì‹¤ì  ê¸°ì¤€")
    print("="*60)
    
    # ëª¨ë¸ ë¡œë“œ
    model = load_ccnet_model()
    
    # ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
    print("\nğŸ“± ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸:")
    dummy_input = torch.randn(1, 1, 128, 128)
    
    with torch.no_grad():
        feature_code = model.getFeatureCode(dummy_input)
        print(f"  íŠ¹ì§• ì½”ë“œ shape: {feature_code.shape}")
        print(f"  ì •ê·œí™” í™•ì¸: {torch.norm(feature_code[0]).item():.6f}")
    
    print(f"\nâœ… ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ì²˜ë¦¬ CCNetì´ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ¯ ì‹¤ì‹œê°„ ì‹œê°í™” ê¸°ëŠ¥ì´ í¬í•¨ëœ ì›¹ ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ¨ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ì²˜ë¦¬ ê¸°ëŠ¥ í™œì„±í™”!")
    print(f"ğŸ“± ì›¹ìº  í™˜ê²½ì— ë§ëŠ” í˜„ì‹¤ì  í’ˆì§ˆ ê¸°ì¤€ ì ìš©!")
    print("="*60)
